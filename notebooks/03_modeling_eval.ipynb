{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67dfbf5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded labeled data: 30,089 rows, 22 columns\n",
      "Campaigns: ['abc_reading', 'electric_toothbrush', 'intelligent_floor_scrubber', 'ruby_face_cream', 'spark_thinking', 'supor_boosted_showerhead']\n",
      "\n",
      "Baseline feature columns: ['log1p_user_followers', 'log1p_user_friends']\n",
      "\n",
      "Full model feature columns: ['log1p_user_followers', 'log1p_user_friends', 'log1p_in_degree', 'log1p_out_degree', 'log1p_pagerank', 'kcore']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "PROC_DIR = Path(\"data/processed\")\n",
    "labeled_path = PROC_DIR / \"features_labeled.parquet\"\n",
    "\n",
    "data = pd.read_parquet(labeled_path)\n",
    "print(f\"Loaded labeled data: {data.shape[0]:,} rows, {data.shape[1]} columns\")\n",
    "print(\"Campaigns:\", sorted(data[\"product_name\"].unique()))\n",
    "\n",
    "# Target\n",
    "TARGET_COL = \"label_high_engagement\"\n",
    "\n",
    "# Baseline: account size only\n",
    "BASELINE_FEATURES = [\n",
    "    \"log1p_user_followers\",\n",
    "    \"log1p_user_friends\",\n",
    "]\n",
    "\n",
    "# Full model: size + network position (no direct engagement counts)\n",
    "FULL_FEATURES = BASELINE_FEATURES + [\n",
    "    \"log1p_in_degree\",\n",
    "    \"log1p_out_degree\",\n",
    "    \"log1p_pagerank\",\n",
    "    \"kcore\",\n",
    "]\n",
    "\n",
    "print(\"\\nBaseline feature columns:\", BASELINE_FEATURES)\n",
    "print(\"\\nFull model feature columns:\", FULL_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1577c15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Campaign: spark_thinking\n",
      "Total rows (candidates): 7,138\n",
      "\n",
      "Train/test split:\n",
      "Train:  4996 rows  positives=1060 (21.2%),  negatives=3936 (78.8%)\n",
      "Test :  2142 rows  positives= 454 (21.2%),  negatives=1688 (78.8%)\n",
      "\n",
      "Test metrics for campaign: spark_thinking\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>p@50</th>\n",
       "      <th>p@100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic_baseline</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.623758</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logistic_full</td>\n",
       "      <td>0.729763</td>\n",
       "      <td>0.889994</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xgboost_full</td>\n",
       "      <td>0.727717</td>\n",
       "      <td>0.911015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model        f1   roc_auc  p@50  p@100\n",
       "0  logistic_baseline  0.000000  0.623758   0.4   0.36\n",
       "1      logistic_full  0.729763  0.889994   1.0   1.00\n",
       "2       xgboost_full  0.727717  0.911015   1.0   1.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 test accounts by xgboost_full score:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>is_official_influencer</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>total_engagement</th>\n",
       "      <th>in_degree</th>\n",
       "      <th>pagerank</th>\n",
       "      <th>label_high_engagement</th>\n",
       "      <th>score_logistic_baseline</th>\n",
       "      <th>score_logistic_full</th>\n",
       "      <th>score_xgb_full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20060</th>\n",
       "      <td>104815</td>\n",
       "      <td>0</td>\n",
       "      <td>11350</td>\n",
       "      <td>2654</td>\n",
       "      <td>165</td>\n",
       "      <td>0.001559</td>\n",
       "      <td>1</td>\n",
       "      <td>0.224648</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.999684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18133</th>\n",
       "      <td>83142</td>\n",
       "      <td>0</td>\n",
       "      <td>698524</td>\n",
       "      <td>2811</td>\n",
       "      <td>907</td>\n",
       "      <td>0.003817</td>\n",
       "      <td>1</td>\n",
       "      <td>0.347959</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18893</th>\n",
       "      <td>88275</td>\n",
       "      <td>0</td>\n",
       "      <td>63501</td>\n",
       "      <td>80</td>\n",
       "      <td>22</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>1</td>\n",
       "      <td>0.283495</td>\n",
       "      <td>0.998950</td>\n",
       "      <td>0.999681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20255</th>\n",
       "      <td>105746</td>\n",
       "      <td>0</td>\n",
       "      <td>18383</td>\n",
       "      <td>107</td>\n",
       "      <td>24</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>1</td>\n",
       "      <td>0.237261</td>\n",
       "      <td>0.999096</td>\n",
       "      <td>0.999677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19470</th>\n",
       "      <td>97952</td>\n",
       "      <td>0</td>\n",
       "      <td>15122</td>\n",
       "      <td>28</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>1</td>\n",
       "      <td>0.232878</td>\n",
       "      <td>0.997246</td>\n",
       "      <td>0.999653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21005</th>\n",
       "      <td>123443</td>\n",
       "      <td>0</td>\n",
       "      <td>145480</td>\n",
       "      <td>2577</td>\n",
       "      <td>206</td>\n",
       "      <td>0.001473</td>\n",
       "      <td>1</td>\n",
       "      <td>0.281977</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18112</th>\n",
       "      <td>83087</td>\n",
       "      <td>0</td>\n",
       "      <td>186930</td>\n",
       "      <td>5524</td>\n",
       "      <td>526</td>\n",
       "      <td>0.005346</td>\n",
       "      <td>1</td>\n",
       "      <td>0.304200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18355</th>\n",
       "      <td>84395</td>\n",
       "      <td>0</td>\n",
       "      <td>23523</td>\n",
       "      <td>106</td>\n",
       "      <td>25</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>1</td>\n",
       "      <td>0.240742</td>\n",
       "      <td>0.999284</td>\n",
       "      <td>0.999621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20864</th>\n",
       "      <td>119321</td>\n",
       "      <td>0</td>\n",
       "      <td>43224</td>\n",
       "      <td>655</td>\n",
       "      <td>80</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>1</td>\n",
       "      <td>0.256487</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18196</th>\n",
       "      <td>83448</td>\n",
       "      <td>0</td>\n",
       "      <td>25037</td>\n",
       "      <td>90</td>\n",
       "      <td>29</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>1</td>\n",
       "      <td>0.241486</td>\n",
       "      <td>0.999601</td>\n",
       "      <td>0.999615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  is_official_influencer  user_followers  total_engagement  \\\n",
       "20060   104815                       0           11350              2654   \n",
       "18133    83142                       0          698524              2811   \n",
       "18893    88275                       0           63501                80   \n",
       "20255   105746                       0           18383               107   \n",
       "19470    97952                       0           15122                28   \n",
       "21005   123443                       0          145480              2577   \n",
       "18112    83087                       0          186930              5524   \n",
       "18355    84395                       0           23523               106   \n",
       "20864   119321                       0           43224               655   \n",
       "18196    83448                       0           25037                90   \n",
       "\n",
       "       in_degree  pagerank  label_high_engagement  score_logistic_baseline  \\\n",
       "20060        165  0.001559                      1                 0.224648   \n",
       "18133        907  0.003817                      1                 0.347959   \n",
       "18893         22  0.000322                      1                 0.283495   \n",
       "20255         24  0.000252                      1                 0.237261   \n",
       "19470         17  0.000332                      1                 0.232878   \n",
       "21005        206  0.001473                      1                 0.281977   \n",
       "18112        526  0.005346                      1                 0.304200   \n",
       "18355         25  0.000377                      1                 0.240742   \n",
       "20864         80  0.000916                      1                 0.256487   \n",
       "18196         29  0.000360                      1                 0.241486   \n",
       "\n",
       "       score_logistic_full  score_xgb_full  \n",
       "20060             0.999999        0.999684  \n",
       "18133             1.000000        0.999683  \n",
       "18893             0.998950        0.999681  \n",
       "20255             0.999096        0.999677  \n",
       "19470             0.997246        0.999653  \n",
       "21005             1.000000        0.999652  \n",
       "18112             1.000000        0.999630  \n",
       "18355             0.999284        0.999621  \n",
       "20864             0.999991        0.999619  \n",
       "18196             0.999601        0.999615  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Pick one campaign here\n",
    "CAMPAIGN = \"spark_thinking\"   # change as needed\n",
    "\n",
    "df_c = data[data[\"product_name\"] == CAMPAIGN].copy()\n",
    "print(f\"Campaign: {CAMPAIGN}\")\n",
    "print(f\"Total rows (candidates): {len(df_c):,}\")\n",
    "\n",
    "# Train/test split (same as before)\n",
    "df_train, df_test = train_test_split(\n",
    "    df_c,\n",
    "    test_size=0.3,\n",
    "    stratify=df_c[TARGET_COL],\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "def label_summary(name, df):\n",
    "    n = len(df)\n",
    "    pos = int(df[TARGET_COL].sum())\n",
    "    neg = n - pos\n",
    "    print(f\"{name}: {n:5d} rows  \"\n",
    "          f\"positives={pos:4d} ({pos/n:5.1%}),  \"\n",
    "          f\"negatives={neg:4d} ({neg/n:5.1%})\")\n",
    "\n",
    "print(\"\\nTrain/test split:\")\n",
    "label_summary(\"Train\", df_train)\n",
    "label_summary(\"Test \", df_test)\n",
    "\n",
    "# Matrices\n",
    "Xb_train = df_train[BASELINE_FEATURES].to_numpy()\n",
    "Xb_test  = df_test[BASELINE_FEATURES].to_numpy()\n",
    "\n",
    "Xf_train = df_train[FULL_FEATURES].to_numpy()\n",
    "Xf_test  = df_test[FULL_FEATURES].to_numpy()\n",
    "\n",
    "y_train = df_train[TARGET_COL].to_numpy()\n",
    "y_test  = df_test[TARGET_COL].to_numpy()\n",
    "\n",
    "# Helper: precision@k\n",
    "def precision_at_k(y_true, y_score, k):\n",
    "    k = min(k, len(y_true))\n",
    "    idx = np.argsort(y_score)[::-1][:k]\n",
    "    return float(y_true[idx].sum()) / k\n",
    "\n",
    "def model_metrics(name, y_true, scores):\n",
    "    y_pred = (scores >= 0.5).astype(int)\n",
    "    return {\n",
    "        \"model\": name,\n",
    "        \"f1\": f1_score(y_true, y_pred),\n",
    "        \"roc_auc\": roc_auc_score(y_true, scores),\n",
    "        \"p@50\": precision_at_k(y_true, scores, 50),\n",
    "        \"p@100\": precision_at_k(y_true, scores, 100),\n",
    "    }\n",
    "\n",
    "metrics = []\n",
    "test_with_scores = df_test.copy()\n",
    "\n",
    "# 1) Logistic, baseline features\n",
    "sc_base = StandardScaler()\n",
    "Xb_train_s = sc_base.fit_transform(Xb_train)\n",
    "Xb_test_s  = sc_base.transform(Xb_test)\n",
    "\n",
    "log_base = LogisticRegression(max_iter=1000, random_state=42)\n",
    "log_base.fit(Xb_train_s, y_train)\n",
    "p_log_base = log_base.predict_proba(Xb_test_s)[:, 1]\n",
    "metrics.append(model_metrics(\"logistic_baseline\", y_test, p_log_base))\n",
    "test_with_scores[\"score_logistic_baseline\"] = p_log_base\n",
    "\n",
    "# 2) Logistic, full features\n",
    "sc_full_log = StandardScaler()\n",
    "Xf_train_s_log = sc_full_log.fit_transform(Xf_train)\n",
    "Xf_test_s_log  = sc_full_log.transform(Xf_test)\n",
    "\n",
    "log_full = LogisticRegression(max_iter=1000, random_state=42)\n",
    "log_full.fit(Xf_train_s_log, y_train)\n",
    "p_log_full = log_full.predict_proba(Xf_test_s_log)[:, 1]\n",
    "metrics.append(model_metrics(\"logistic_full\", y_test, p_log_full))\n",
    "test_with_scores[\"score_logistic_full\"] = p_log_full\n",
    "\n",
    "# 3) XGBoost, full features\n",
    "sc_full_xgb = StandardScaler()\n",
    "Xf_train_s_xgb = sc_full_xgb.fit_transform(Xf_train)\n",
    "Xf_test_s_xgb  = sc_full_xgb.transform(Xf_test)\n",
    "\n",
    "xgb_full = XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    n_estimators=200,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "xgb_full.fit(Xf_train_s_xgb, y_train)\n",
    "p_xgb_full = xgb_full.predict_proba(Xf_test_s_xgb)[:, 1]\n",
    "metrics.append(model_metrics(\"xgboost_full\", y_test, p_xgb_full))\n",
    "test_with_scores[\"score_xgb_full\"] = p_xgb_full\n",
    "\n",
    "print(\"\\nTest metrics for campaign:\", CAMPAIGN)\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "display(metrics_df)\n",
    "\n",
    "# See top 10 test accounts by xgboost_full score\n",
    "cols_show = [\n",
    "    \"user_id\",\n",
    "    \"is_official_influencer\",\n",
    "    \"user_followers\",\n",
    "    \"total_engagement\",\n",
    "    \"in_degree\",\n",
    "    \"pagerank\",\n",
    "    TARGET_COL,\n",
    "    \"score_logistic_baseline\",\n",
    "    \"score_logistic_full\",\n",
    "    \"score_xgb_full\",\n",
    "]\n",
    "\n",
    "print(\"\\nTop 10 test accounts by xgboost_full score:\")\n",
    "display(\n",
    "    test_with_scores.sort_values(\"score_xgb_full\", ascending=False)[cols_show].head(10)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "influence-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
